How to use 

1. copy `eval_fn/` to your evaluation result folder, for example：`Multigen_Eval_history/grf-in_domain_eval` is one of result folder of Multigen, so it becomes：

        eval_fn/ ---> Multigen_Eval_history/grf-in_domain_eval/eval_fn/

2. evaluation *perplexity* with GPT-2：

    - Name of prediction file generated by two model are different
    - for Multigen：

            python3 ppl_test_preprocess.py --source_file ../source.csv --predict_out_file ../result_ep\:test.txt
            

    - for T5-small：
    
            python3 ppl_test_preprocess.py --source_file ../source.csv --predict_out_file ../result_ep\:test.txt